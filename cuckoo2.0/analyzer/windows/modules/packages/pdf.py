# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2016 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import logging
import os
import mmap
import re
import sys
import subprocess
import time
import tempfile

from packUtils import *

from _winreg import HKEY_LOCAL_MACHINE, HKEY_CURRENT_USER

from lib.common.abstracts import Package

log = logging.getLogger(__name__)


standardURLs = ["ns.adobe.com","purl.org","w3.org"]

def isStandardURL(inURL):
	#Search if this URL is part of standard URLs
	for url in standardURLs:
		if url in inURL:
			return True

	return False

try:
      import peepdf.PDFCore
      import peepdf.JSAnalysis
      HAVE_PEEPDF = True
except ImportError:
      HAVE_PEEPDF = False




class PDF(Package):
    """PDF analysis package."""
    PATHS = [
        ("ProgramFiles", "Adobe", "Reader 8.0", "Reader", "AcroRd32.exe"),
        ("ProgramFiles", "Adobe", "Reader 9.0", "Reader", "AcroRd32.exe"),
        ("ProgramFiles", "Adobe", "Reader 10.0", "Reader", "AcroRd32.exe"),
        ("ProgramFiles", "Adobe", "Reader 11.0", "Reader", "AcroRd32.exe"),
        ("ProgramFiles", "Adobe", "Acrobat Reader DC", "Reader", "AcroRd32.exe"),
	("ProgramFiles", "Internet Explorer", "iexplore.exe"),
    ]

    REGKEYS = [
        [
            HKEY_LOCAL_MACHINE,
            "SOFTWARE\\Adobe\\Acrobat Reader\\9.0\\AdobeViewer",
            {
                # Accept EULA for Adobe Reader 9.0.
                "EULA": 1,
            },
        ],
        [
            HKEY_CURRENT_USER,
            "SOFTWARE\\Adobe\\Acrobat Reader\\9.0\\AdobeViewer",
            {
                # Accept EULA for Adobe Reader 9.0.
                "EULA": 1,
            },
        ],
    ]

    
    def get_urls(self,filepath):

	retUrls = []
	if not HAVE_PEEPDF:
		log.info("No PeePDF, getting  URLs through regex")
		if not os.path.getsize(filepath):
	             return retUrls
 
	        # http://stackoverflow.com/a/454589
        	urls = set()
	        f = open(filepath, "rb")
        	m = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)
 
	        for url in re.findall(URL_REGEX, m):
			tempurl = "".join(url)
			if isStandardURL(tempurl):
				log.info("Is Standard URL, not adding to list")
				log.info(tempurl)
				continue
			urls.add("".join(url))
		 
	        return list(urls)

	log.info("Has PeePDF")
	p = peepdf.PDFCore.PDFParser()
        r, f = p.parse(
             filepath, forceMode=True,
             looseMode=True, manualAnalysis=False)
        if r:
             log.warning("Error parsing PDF file, error code %s", r)
             return retUrls

	for version in xrange(f.updates + 1):
		 for obj in f.body[version].objects.values():
			if obj.object.type == "dictionary":
                  	   	for url in obj.object.urlsFound:
                        	 	retUrls.append(self._parse_string(url))
 
	                        for url in obj.object.uriList:
           		                retUrls.append(self._parse_string(url))

	return retUrls


    def create_url_file(self,urls):
	retName = ""
	try:
		fd,name = tempfile.mkstemp(suffix=".py",dir="C:\\Dlls\\")
		log.info("TempFile %s",name)
		curfile = open(name,'w')
		curfile.write("listUrls=[")
		for url in urls:
			if url.endswith(")"):
				url=url[:-1]
			curfile.write("\"")
			curfile.write(url)
			curfile.write("\"")
			curfile.write(",")
			log.info(url)
		curfile.write("]")
		curfile.write("\n")

		with open("C:\\Dlls\\tempate-pdf-python.py",'r') as content_file:
			contents = content_file.read()
			curfile.write(contents)

		curfile.close()
		retName = name

	except:
		e = sys.exc_info()[0]
                log.error(str(e))
		e1 = sys.exc_info()[1]
                log.error(str(e1))

	return retName

    def start(self, path):
        reader = self.get_path("Adobe Reader")

        # Enforce the .pdf file extension.
        if not path.endswith(".pdf"):
            os.rename(path, path + ".pdf")
            path += ".pdf"
            log.info("Submitted file is missing extension, added .pdf")

		
        pid =  self.execute(
            reader, args=[path], maximize=True, mode="pdf",
            trigger="file:%s" % path
        )

	curUrls = self.get_urls(path)

	if len(curUrls)>0:
		log.info("Has non-zero URLs")

		newFile = self.create_url_file(curUrls)

		run_package(self,"python",newFile)

	else:
		log.info("No URLs found")


	return pid
	
